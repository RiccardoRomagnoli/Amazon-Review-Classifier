{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Natural Language Processing for Classifying Amazon Reviews.\n",
    "## Sentiment Analysis\n",
    "\n",
    "Riccardo Romagnoli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLTK\n",
    "\n",
    "- _NLTK_ (_Natural Language Toolkit_) one of the primary lib in Python fr managing natual language data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some specific feature of nltk will be downloaded during the notebook with the function `download`. This data will be stored in the dir `nltk_data` in our home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Segmentation\n",
    "\n",
    "- NLTK offers the `word_tokenize` function to decompose a string into a list of words and punctuation marks\n",
    "- The function uses an English language model to correctly break down some words\n",
    "- We use the `download` function to download that template (if not already downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\98ric\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bag of Words e Vector Space Model\n",
    "\n",
    "- We will make use of the model Bag of Words and Vector Space Model for keeping track of the occurencies for each word for each document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Case Study: Classification of Reviews\n",
    "\n",
    "- Users' opinions are continuously published on the web, eg. of movies\n",
    "   - some of these (e.g. on Amazon) are labeled with a number of stars, which indicate whether it is positive or negative\n",
    "   - on others (eg messages on forums) we do not have this structured information, but only the text\n",
    "- We want to train a classifier on reviews labeled as positive or negative, so that he is able to estimate the sentiment of untagged text\n",
    "- We use a file of 10,000 movie reviews retreived from Amazon. Each review  has a rating from 1 to 5 stars\n",
    "- Using the vector space model, we can train a model on the counts of all the words present in the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"reviews.csv.gz\"):\n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(\"https://git.io/Jmwrd\", \"reviews.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"reviews.csv.gz\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The file contains two columns\n",
    "   - in `text` we find the text of the review\n",
    "   - in `stars` we find the number of stars given by the user, from 1 to 5\n",
    "- Let's look at some lines of the dataset; first let's increase the number of characters displayed per col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>WHAT CAN I SAY THIS PPV WAS AWFUL WITH ONLY A FEW DECENT MATCHES.The best match was The stretche...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>La Resistance vs Dudley boyz-Good tag team match up.There were great moves,good action and a sho...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>Dudley boyz vs French guys-Exellent tables match and a great opener.It was good to see all 3 mem...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>Survivor series 2003 had alot on the line including jobs,titles and lives in the burried alive m...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>Dudley Boyz VS Ric Flair and Batista: This match was rather short. Dudley's looked good but Coac...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>You seen one heist film, you seen them all. But every once in a while, somebody who really gives...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Often compared with \"The Big Chill\", and getting numerous stars in many reviews, this film simpl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>This collection of Laurel and Hardy films contains five total selections.  Four of these are sho...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>I love Vin Diesel but I wish I'd skipped this movie. The first bad sign was the fact that this t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>When The Office was first shown to a UK audience back in 2001, it was shown on BBC2. That is the...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                     text  \\\n",
       "9990  WHAT CAN I SAY THIS PPV WAS AWFUL WITH ONLY A FEW DECENT MATCHES.The best match was The stretche...   \n",
       "9991  La Resistance vs Dudley boyz-Good tag team match up.There were great moves,good action and a sho...   \n",
       "9992  Dudley boyz vs French guys-Exellent tables match and a great opener.It was good to see all 3 mem...   \n",
       "9993  Survivor series 2003 had alot on the line including jobs,titles and lives in the burried alive m...   \n",
       "9994  Dudley Boyz VS Ric Flair and Batista: This match was rather short. Dudley's looked good but Coac...   \n",
       "9995  You seen one heist film, you seen them all. But every once in a while, somebody who really gives...   \n",
       "9996  Often compared with \"The Big Chill\", and getting numerous stars in many reviews, this film simpl...   \n",
       "9997  This collection of Laurel and Hardy films contains five total selections.  Four of these are sho...   \n",
       "9998  I love Vin Diesel but I wish I'd skipped this movie. The first bad sign was the fact that this t...   \n",
       "9999  When The Office was first shown to a UK audience back in 2001, it was shown on BBC2. That is the...   \n",
       "\n",
       "      stars  \n",
       "9990      2  \n",
       "9991      4  \n",
       "9992      5  \n",
       "9993      4  \n",
       "9994      4  \n",
       "9995      5  \n",
       "9996      1  \n",
       "9997      3  \n",
       "9998      3  \n",
       "9999      5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    4708\n",
       "4    2620\n",
       "3    1434\n",
       "2     704\n",
       "1     534\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"stars\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews[\"stars\"].value_counts().plot.pie();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews[\"text\"].str.len().plot.hist(bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Suddivision in negative and positive reviews\n",
    "\n",
    "- To simplify the analysis, we reduce the 5 possible star numbers to two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"label\"] = np.where(reviews[\"stars\"] >= 4, \"pos\", \"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    7328\n",
       "neg    2672\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification of texts\n",
    "\n",
    "- The documents-terms matrix has the form of a dataset\n",
    "   - each line represents an example (a text) to be classified\n",
    "   - each column represents a variable that characterizes the examples\n",
    "- On this matrix we can then train a classifier to estimate the sentiment of the reviews\n",
    "- Let's start by dividing the data into training set (70 \\%) and validation set (30 \\%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "reviews_train, reviews_val = \\\n",
    "    train_test_split(reviews, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_train = vect.fit_transform(reviews_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51772"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Some examples of extracted words are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abides',\n",
       " 'abiding',\n",
       " 'abigail',\n",
       " 'abilene',\n",
       " 'abilites',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abit',\n",
       " 'abition',\n",
       " 'abject']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[1000:1010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " - We are working with sparse matrix as the percentage of non-zero elements is very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7000x51772 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 993179 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002740529905850931"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_train.astype(bool).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we represent the documents of the valitation set trasforming the previous vectorial space, we get back the corrispondent matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_val = vect.transform(reviews_val[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- At this point we create a classification model and train it by passing the documents-terms matrix and the reviews labels related to the training set. We use logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\98ric\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrm = LogisticRegression(solver=\"saga\", C=10)\n",
    "lrm.fit(dtm_train, reviews_train[\"label\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can estimate the accuracy using the validation labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7996666666666666"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm.score(dtm_val, reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model assumes `neg` as _negative_ class (-1) and` pos` as _positive_ (1), as deduced from the order of the two in the attribute `classes_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg', 'pos'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use the model\n",
    "\n",
    "- We can consider the following set of reviews to classify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews = [\"What an awesome movie!\", \"It was really boring\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_new = vect.transform(new_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'neg'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm.predict(dtm_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45271932, 0.54728068],\n",
       "       [0.54860307, 0.45139693]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm.predict_proba(dtm_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Better understanding the model: parameters\n",
    "\n",
    "- We can access the linear coefficients assigned to the model for each term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00122182,  0.00551732,  0.00096862, -0.00018462])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm.coef_[0, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can associate the feature name to the param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.Series(lrm.coef_[0], index=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sorting this series we can see which are the highest and lowest coefficients and from these: which words contribute most to make a positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.sort_values(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad       -0.280119\n",
       "nothing   -0.204467\n",
       "worst     -0.183651\n",
       "plot      -0.181641\n",
       "just      -0.155580\n",
       "if        -0.151799\n",
       "boring    -0.138702\n",
       "decent    -0.134982\n",
       "minutes   -0.134170\n",
       "but       -0.134041\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season       0.156078\n",
       "very         0.167034\n",
       "you          0.177193\n",
       "well         0.180045\n",
       "love         0.180249\n",
       "highly       0.180372\n",
       "excellent    0.204739\n",
       "dvd          0.206031\n",
       "best         0.213090\n",
       "great        0.420797\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's make use of a Pipeline for doing pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer()),\n",
    "    (\"classifier\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\98ric\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highly       0.180323\n",
       "excellent    0.204698\n",
       "dvd          0.206369\n",
       "best         0.213940\n",
       "great        0.420778\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(\n",
    "    model.named_steps[\"classifier\"].coef_[0],\n",
    "    index=model.named_steps[\"vectorizer\"].get_feature_names()\n",
    ").sort_values().tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## tf.idf\n",
    "\n",
    "- We can use _tf.idf_ (_term frequency-inverse document frequency_), to weigh the relevance of each term in a document\n",
    "    - the _tf_ indicates the **local importance** of a term in a document and is equal to the number of occurrences (or its logarithm)\n",
    "    - the_idf_ indicates the **global importance** of a term, the higher the more the term is less common in the overall set of documents\n",
    "    - commonly, once all weights have been calculated, **each vector is normalized** in order to have Euclidean norm equal to 1, to smooth out differences in weights between short and long documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer()),\n",
    "    (\"classifier\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train a model on the training set and evaluate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"])\n",
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Breakdown in terms with NLTK\n",
    "\n",
    "- We can use the param `tokenizer` to specify a non standard logic to split the strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8223333333333334"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(tokenizer=nltk.word_tokenize)),\n",
    "    (\"classifier\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"])\n",
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We actually get a slightly less accurate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reduce dimensionality\n",
    "\n",
    "- The number of dimensions generated considering all the distinct terms present in all the documents, as also seen above, is very high. That can cause a longer execution time and an excessive use of memory. We will now try to reduce the dimensionality without loosing too much accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72503"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vectorizer\"].get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can set the parameter `min_df` in `TfidfVectorizer` (or `CountVectorizer`) to limit the words in the vector space dictionary to those present in at least _N_ training documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(min_df=3)),\n",
    "    (\"classifier\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We just N = 3 we obtain a much lighter model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21063"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vectorizer\"].get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While keeping the same accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226666666666667"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stopword removal\n",
    "\n",
    "- We use NLTK lists to remove stopwords: terms that doen't add any informative content (articles, prepositions, coniugations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\98ric\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We use the param _stop_words_ to insert our list of stopwords we want to remove from the feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(min_df=3, stop_words=stoplist)),\n",
    "    (\"classifier\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We get a lower feature set in change of some points in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20922"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vectorizer\"].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.809"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grid search to find best hyperparameters\n",
    "Here we are testing:\n",
    "    - minimum number of documents in which a word must appear: 3, 5 or 10\n",
    "    - removal/no removal of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer()),\n",
    "    (\"classifier\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "grid = {\n",
    "    \"vectorizer__min_df\": [3, 5, 10],\n",
    "    \"vectorizer__stop_words\": [None, stoplist]\n",
    "}\n",
    "skf = StratifiedKFold(3, shuffle=True)\n",
    "gs = GridSearchCV(model, grid, cv=skf)\n",
    "gs.fit(reviews_train[\"text\"], reviews_train[\"label\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226666666666667"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## n-gram\n",
    "\n",
    "- A _n-gram_ is a **sequence of consecutive words** in a text, we can specify that in order to consider words that make sense taking togheder.\n",
    "- Drawback -> higher dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(min_df=3, ngram_range=(1, 2))),\n",
    "    (\"classifier\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100711"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vectorizer\"].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8233333333333334"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zone and',\n",
       " 'zone feel',\n",
       " 'zone the',\n",
       " 'zones',\n",
       " 'zoo',\n",
       " 'zooey',\n",
       " 'zooey deschanel',\n",
       " 'zoolander',\n",
       " 'zoom',\n",
       " 'zooming']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"vectorizer\"].get_feature_names()[-15:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## POS Tagging\n",
    "\n",
    "- We try to add the _Part of Speech_ (POS) information to the token as a tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\98ric\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_pos(text):\n",
    "    return nltk.pos_tag(nltk.tokenize.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(min_df=3, tokenizer=tokenize_with_pos)),\n",
    "    (\"classifier\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26839"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vectorizer\"].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156666666666667"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not much difference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lemmatization\n",
    "\n",
    "- With lemmatization we **group similar terms** under the same word. By doing that we reduce the dimensionality of the space without loss of relevant information\n",
    "- To perform the lemmatization in NLTK we create a `WordNetLemmatizer` object and we also need to download the WordNet knowledge base, which includes the necessary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\98ric\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- To lemmatize a word, use the `lemmatize` method, passing also the POS (n = noun, v = verb, a = adjective, r = adverb)\n",
    "- We create a function that segments the words of a text by performing lemmatization where possible\n",
    "- we create a dictionary with the correspondences between the first letters of the POS in Penn Treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "penn_to_wn = {\"N\": \"n\", \"V\": \"v\", \"J\": \"a\", \"R\": \"r\"}\n",
    "def tokenize_with_lemmatization(text):\n",
    "    return [(wnl.lemmatize(token, penn_to_wn[tag[0]]) if tag[0] in penn_to_wn else token)\n",
    "            for token, tag in nltk.pos_tag(nltk.tokenize.word_tokenize(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(min_df=3, tokenizer=tokenize_with_lemmatization)),\n",
    "    (\"classifier\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a result we get a lower number of features, however the time taken for processing the text is higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18152"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vectorizer\"].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stemming\n",
    "\n",
    "We use A _stemming_ algorithm to extracts the **morphological root** of a word, which results in:\n",
    "    - terms with the same root are often correlated, although they are different terms (eg name \"fish\" and verb \"fishing\")\n",
    "    - stemming does not require POS tagging and is generally much more efficient\n",
    "- NLTK integrates several stemming algorithms, including eg. `PorterStemmer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lemmat', 'lemmat', 'lemmat')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.stem.PorterStemmer()\n",
    "ps.stem(\"lemmatization\"), ps.stem(\"lemmatizer\"), ps.stem(\"lemmatize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_stemming(text):\n",
    "    return [ps.stem(token) for token\n",
    "            in nltk.word_tokenize(text)]\n",
    "    # or: return list(map(ps.stem, nltk.word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(min_df=3, tokenizer=tokenize_with_stemming)),\n",
    "    (\"classifier\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15926"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vectorizer\"].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8223333333333334"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to have an even lower in dimensionality without losing accuracy at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sentiment Analysis in NLTK\n",
    "\n",
    "- Estimating the positive or negative orientation of written opinions is a very common problem\n",
    "- There are pre-trained models for this, including [_VADER_] (https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8109) (_Valence Aware Dictionary and sEntiment Reasoner_)\n",
    "- NLTK allows us to use VADER to evaluate the orientation of opinions, without the need to train models\n",
    "- To use VADER, we download the necessary data and create a `SentimentIntensityAnalyzer` object. We then will predict our evaluation instances and compare the accuracy with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\98ric\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We created a function in order to use VANDER in our specific use case. That function will sum all the compount (one of the return values from _vader.polarity_scores_) result for each sentence of each text. If the value is positive then the sentiment is positive, negative elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_review(review):\n",
    "    sentences = nltk.sent_tokenize(review)\n",
    "    scores = list(map(vader.polarity_scores, sentences))\n",
    "    return \"pos\" if sum(s[\"compound\"] for s in scores) >= 0 else \"neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_preds = [label_review(review) for review in reviews_val[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7303333333333333"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(reviews_val[\"label\"], vader_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model actually performs better, but we also have to say that VANDER is majorly trained on twitter messages while out model right on the data in question."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
